ğŸ•·ï¸ Mini Scraper (Scrapy + Playwright)

A small educational project for professional Web Scraping built with:

Python 3.10+

Scrapy

Playwright

Mirror-style crawler (downloads HTML, CSS, JS, images)

Automatic daily execution with cron

The scraper can:
````
âœ… Render JavaScript (dynamic websites)
âœ… Download full HTML
âœ… Download CSS, JS, TS, and images
âœ… Avoid duplicate URLs
âœ… Save files in an organized folder structure
âœ… Run automatically every day
````
ğŸ“ Project Structure
````
mini-scraper/
â”‚
â”œâ”€â”€ scrapy.cfg
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ run.sh
â”œâ”€â”€ .env
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ site-example.com/
â”‚        â”œâ”€â”€ html/
â”‚        â”œâ”€â”€ css/
â”‚        â”œâ”€â”€ js/
â”‚        â”œâ”€â”€ ts/
â”‚        â””â”€â”€ images/
â”‚
â””â”€â”€ mini-scraper/
    â”œâ”€â”€ items.py
    â”œâ”€â”€ pipelines.py
    â”œâ”€â”€ settings.py
    â””â”€â”€ spiders/
        â””â”€â”€ first_spider.py
````
ğŸš€ Step-by-step Installation
1ï¸âƒ£ Create virtual environment

Linux / macOS:
````
python3 -m venv venv
source venv/bin/activate
````

Windows:

```nv\Scripts\activate

2ï¸âƒ£ Install Python dependencies
pip install -r requirements.txt

3ï¸âƒ£ Install Playwright browsers
```
IMPORTANT (first time only):

`playwright install`


Linux (if system libraries are missing):

`playwright install-deps`

âš™ï¸ Configuration
.env

Define the target URL:

START_URL=https://quotes.toscrape.com/


You can replace it with:
```
https://www.amazon.com/s?k=laptop
https://example.com
https://your-local-store.com
```

â–¶ï¸ Run the scraper

Inside the virtual environment:

`scrapy crawl products`

ğŸ“‚ Output

The scraper automatically generates:

```
data/
 â””â”€â”€ site-quotes.toscrape.com/
      â”œâ”€â”€ html/
      â”œâ”€â”€ css/
      â”œâ”€â”€ js/
      â”œâ”€â”€ ts/
      â””â”€â”€ images/

```
Each resource is saved physically:

Example:
````
html/index.html
css/main.css
js/app.js
images/logo.png
````

ğŸ‘‰ This creates an offline mirror of the website.

â° Automatic execution with CRON (Linux/Mac)

Edit crontab:

`crontab -e`


Run daily at 3 AM:

`0 3 * * * /path/to/mini-scraper/run.sh >> scraper.log 2>&1`

ğŸ§  Technologies Used
````
Tool	Purpose
Scrapy	Main crawler
Playwright	JavaScript rendering
Python	Scraping logic
Cron	Automation
````

ğŸ”¥ Best Practices Implemented
````
âœ” Virtual environment
âœ” .env configuration
âœ” .gitignore
âœ” Organized resource folders
âœ” No duplicate downloads
âœ” Compatible with dynamic websites
âœ” Modular code
````
ğŸ§ª Use Cases
````
This project can be used for:

Professional web scraping

Static website mirroring

SEO audits

Offline HTML analysis

Extracting data from e-commerce sites

Academic scraping experiments
````
âš ï¸ Legal Notice

Use this project only for:

âœ… learning
âœ… testing
âœ… your own websites
âœ… websites with permission

Always respect robots.txt and website terms of service.